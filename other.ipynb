{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "631fb974",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow Version:  2.5.0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import cv2\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import keras\n",
    "import time\n",
    "import random\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "# from image_slicer import slice\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras import layers, models\n",
    "\n",
    "print(\"TensorFlow Version: \", tf.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8e01ce01",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data():\n",
    "    \"\"\" \n",
    "        Prepares data.\n",
    "            Coverts and combines all images to the size of (32x32) from the Chars74k Dataset and\n",
    "            The CIFAR10 dataset from tensorflow.keras.datasets library.\n",
    "            \n",
    "            Labels Images from Chars74k dataset as 1.\n",
    "            Labels Images from CIFAR10 dataset as 0.\n",
    "    \"\"\"\n",
    "    def prepare_char74k():\n",
    "        \n",
    "        charset = \"./datasets/charset74k/Img/GoodImg/Bmp\"\n",
    "        dirlist = os.listdir(charset)\n",
    "        charImgList = []\n",
    "        for x in dirlist:\n",
    "            img_list = os.listdir(charset + \"/\" + x)\n",
    "            for img in img_list:\n",
    "                cur_img = cv2.imread(charset + \"/\" + x + \"/\" + img)\n",
    "                cur_img = cv2.resize(cur_img, (32,32))\n",
    "                charImgList.append(cur_img)\n",
    "            print(\"Added: \" + charset + \"/\" + x )\n",
    "        charset = \"./datasets/charset74k/Img/BadImag/Bmp\"\n",
    "        dirlist = os.listdir(charset)\n",
    "        for x in dirlist:\n",
    "            img_list = os.listdir(charset + \"/\" + x)\n",
    "            for img in img_list:\n",
    "                cur_img = cv2.imread(charset + \"/\" + x + \"/\" + img)\n",
    "                cur_img = cv2.resize(cur_img, (32,32))\n",
    "                charImgList.append(cur_img)\n",
    "            print(\"Added: \" + charset + \"/\" + x )\n",
    "        print(\"---------IMG ADDED----------\")\n",
    "        charset = \"./datasets/charset74k/Hnd/Img\"\n",
    "        dirlist = os.listdir(charset)\n",
    "        for x in dirlist:\n",
    "            img_list = os.listdir(charset + \"/\" + x)\n",
    "            for img in img_list:\n",
    "                cur_img = cv2.imread(charset + \"/\" + x + \"/\" + img)\n",
    "                cur_img = cv2.resize(cur_img, (32,32))\n",
    "                charImgList.append(cur_img)\n",
    "            print(\"Added: \" + charset + \"/\" + x )\n",
    "        print(\"---------HAND ADDED----------\")\n",
    "        charset = \"./datasets/charset74k/Fnt\"\n",
    "        dirlist = os.listdir(charset)\n",
    "        for x in dirlist:\n",
    "            img_list = os.listdir(charset + \"/\" + x)\n",
    "            for img in img_list:\n",
    "                cur_img = cv2.imread(charset + \"/\" + x + \"/\" + img)\n",
    "                cur_img = cv2.resize(cur_img, (32,32))\n",
    "                charImgList.append(cur_img)\n",
    "            print(\"Added: \" + charset + \"/\" + x )\n",
    "        print(\"---------FONT ADDED----------\")\n",
    "        charImgList = np.array(charImgList)\n",
    "        charImgLabels = np.ones([len(charImgList), 1])\n",
    "        return (charImgList, charImgLabels)\n",
    "    \n",
    "    def prepare_cifar10():\n",
    "        (cifx_1, _), ( cifx_2, _) = tf.keras.datasets.cifar10.load_data()\n",
    "        #Taking only the Features and leaving out the labels\n",
    "        cifx = np.concatenate((cifx_1, cifx_2))\n",
    "#         print(cifx.shape)\n",
    "        print(\"CIFAR10 Added\")\n",
    "        return (cifx, np.zeros([len(cifx), 1])) \n",
    "\n",
    "    char_X, char_label = prepare_char74k()\n",
    "    \n",
    "    sliceImgList = []\n",
    "    l = len(char_X)\n",
    "    for _ in range(2000):\n",
    "        i = random.randrange(l)\n",
    "        j = random.randrange(l)\n",
    "        \n",
    "        img1 = char_X[i]\n",
    "        img2 = char_X[j]\n",
    "        img = cv2.hconcat([img1, img2])\n",
    "        sliceImgList.append(cv2.resize(img[:,16:47], (32,32)))\n",
    "        img = cv2.vconcat([img1,img2])[16:47,:]\n",
    "        sliceImgList.append(cv2.resize(img, (32,32)))\n",
    "        if(len(sliceImgList)%1000 == 0):\n",
    "            print(len(sliceImgList), \"In betweens\")\n",
    "    si_x = np.array(sliceImgList, dtype = object)\n",
    "    plt.imshow(sliceImgList[0])\n",
    "    si_label = np.zeros([len(si_x), 1])\n",
    "    \n",
    "    sliImgList = []\n",
    "    for _ in range(1000):\n",
    "        i = random.randrange(l)\n",
    "        img1 = cv2.resize(char_X[i][:,10:32], (32,32))\n",
    "        img2 = cv2.resize(char_X[i][:,0:22], (32,32))\n",
    "        img3 = cv2.resize(char_X[i][10:32,:], (32,32))\n",
    "        img4 = cv2.resize(char_X[i][0:22,:], (32,32))\n",
    "        sliImgList.append(img1)\n",
    "        sliImgList.append(img2)\n",
    "        sliImgList.append(img3)\n",
    "        sliImgList.append(img4)\n",
    "    sli_x = np.array(sliImgList, dtype=object)\n",
    "    sli_label = np.zeros([len(sli_x), 1])\n",
    "        \n",
    "    (cif_X,cif_label) = prepare_cifar10()\n",
    "\n",
    "    X = np.concatenate((char_X, cif_X))\n",
    "    X = np.concatenate((X,si_x))\n",
    "    X = np.concatenate((X,sli_x))\n",
    "    Y = np.concatenate((char_label, cif_label))\n",
    "    Y = np.concatenate((Y, si_label))\n",
    "    Y = np.concatenate((Y, sli_label))\n",
    "    return (X,Y)\n",
    "#     return prepare_char74k()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f2e0b63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added: ./datasets/charset74k/Img/GoodImg/Bmp/Sample001\n",
      "Added: ./datasets/charset74k/Img/GoodImg/Bmp/Sample002\n",
      "Added: ./datasets/charset74k/Img/GoodImg/Bmp/Sample003\n",
      "Added: ./datasets/charset74k/Img/GoodImg/Bmp/Sample004\n",
      "Added: ./datasets/charset74k/Img/GoodImg/Bmp/Sample005\n",
      "Added: ./datasets/charset74k/Img/GoodImg/Bmp/Sample006\n",
      "Added: ./datasets/charset74k/Img/GoodImg/Bmp/Sample007\n",
      "Added: ./datasets/charset74k/Img/GoodImg/Bmp/Sample008\n",
      "Added: ./datasets/charset74k/Img/GoodImg/Bmp/Sample009\n",
      "Added: ./datasets/charset74k/Img/GoodImg/Bmp/Sample010\n",
      "Added: ./datasets/charset74k/Img/GoodImg/Bmp/Sample011\n",
      "Added: ./datasets/charset74k/Img/GoodImg/Bmp/Sample012\n",
      "Added: ./datasets/charset74k/Img/GoodImg/Bmp/Sample013\n",
      "Added: ./datasets/charset74k/Img/GoodImg/Bmp/Sample014\n",
      "Added: ./datasets/charset74k/Img/GoodImg/Bmp/Sample015\n",
      "Added: ./datasets/charset74k/Img/GoodImg/Bmp/Sample016\n",
      "Added: ./datasets/charset74k/Img/GoodImg/Bmp/Sample017\n",
      "Added: ./datasets/charset74k/Img/GoodImg/Bmp/Sample018\n",
      "Added: ./datasets/charset74k/Img/GoodImg/Bmp/Sample019\n",
      "Added: ./datasets/charset74k/Img/GoodImg/Bmp/Sample020\n",
      "Added: ./datasets/charset74k/Img/GoodImg/Bmp/Sample021\n",
      "Added: ./datasets/charset74k/Img/GoodImg/Bmp/Sample022\n",
      "Added: ./datasets/charset74k/Img/GoodImg/Bmp/Sample023\n",
      "Added: ./datasets/charset74k/Img/GoodImg/Bmp/Sample024\n",
      "Added: ./datasets/charset74k/Img/GoodImg/Bmp/Sample025\n",
      "Added: ./datasets/charset74k/Img/GoodImg/Bmp/Sample026\n",
      "Added: ./datasets/charset74k/Img/GoodImg/Bmp/Sample027\n",
      "Added: ./datasets/charset74k/Img/GoodImg/Bmp/Sample028\n",
      "Added: ./datasets/charset74k/Img/GoodImg/Bmp/Sample029\n",
      "Added: ./datasets/charset74k/Img/GoodImg/Bmp/Sample030\n",
      "Added: ./datasets/charset74k/Img/GoodImg/Bmp/Sample031\n",
      "Added: ./datasets/charset74k/Img/GoodImg/Bmp/Sample032\n",
      "Added: ./datasets/charset74k/Img/GoodImg/Bmp/Sample033\n",
      "Added: ./datasets/charset74k/Img/GoodImg/Bmp/Sample034\n",
      "Added: ./datasets/charset74k/Img/GoodImg/Bmp/Sample035\n",
      "Added: ./datasets/charset74k/Img/GoodImg/Bmp/Sample036\n",
      "Added: ./datasets/charset74k/Img/GoodImg/Bmp/Sample037\n",
      "Added: ./datasets/charset74k/Img/GoodImg/Bmp/Sample038\n",
      "Added: ./datasets/charset74k/Img/GoodImg/Bmp/Sample039\n",
      "Added: ./datasets/charset74k/Img/GoodImg/Bmp/Sample040\n",
      "Added: ./datasets/charset74k/Img/GoodImg/Bmp/Sample041\n",
      "Added: ./datasets/charset74k/Img/GoodImg/Bmp/Sample042\n",
      "Added: ./datasets/charset74k/Img/GoodImg/Bmp/Sample043\n",
      "Added: ./datasets/charset74k/Img/GoodImg/Bmp/Sample044\n",
      "Added: ./datasets/charset74k/Img/GoodImg/Bmp/Sample045\n",
      "Added: ./datasets/charset74k/Img/GoodImg/Bmp/Sample046\n",
      "Added: ./datasets/charset74k/Img/GoodImg/Bmp/Sample047\n",
      "Added: ./datasets/charset74k/Img/GoodImg/Bmp/Sample048\n",
      "Added: ./datasets/charset74k/Img/GoodImg/Bmp/Sample049\n",
      "Added: ./datasets/charset74k/Img/GoodImg/Bmp/Sample050\n",
      "Added: ./datasets/charset74k/Img/GoodImg/Bmp/Sample051\n",
      "Added: ./datasets/charset74k/Img/GoodImg/Bmp/Sample052\n",
      "Added: ./datasets/charset74k/Img/GoodImg/Bmp/Sample053\n",
      "Added: ./datasets/charset74k/Img/GoodImg/Bmp/Sample054\n",
      "Added: ./datasets/charset74k/Img/GoodImg/Bmp/Sample055\n",
      "Added: ./datasets/charset74k/Img/GoodImg/Bmp/Sample056\n",
      "Added: ./datasets/charset74k/Img/GoodImg/Bmp/Sample057\n",
      "Added: ./datasets/charset74k/Img/GoodImg/Bmp/Sample058\n",
      "Added: ./datasets/charset74k/Img/GoodImg/Bmp/Sample059\n",
      "Added: ./datasets/charset74k/Img/GoodImg/Bmp/Sample060\n",
      "Added: ./datasets/charset74k/Img/GoodImg/Bmp/Sample061\n",
      "Added: ./datasets/charset74k/Img/GoodImg/Bmp/Sample062\n",
      "Added: ./datasets/charset74k/Img/BadImag/Bmp/Sample001\n",
      "Added: ./datasets/charset74k/Img/BadImag/Bmp/Sample002\n",
      "Added: ./datasets/charset74k/Img/BadImag/Bmp/Sample003\n",
      "Added: ./datasets/charset74k/Img/BadImag/Bmp/Sample004\n",
      "Added: ./datasets/charset74k/Img/BadImag/Bmp/Sample005\n",
      "Added: ./datasets/charset74k/Img/BadImag/Bmp/Sample006\n",
      "Added: ./datasets/charset74k/Img/BadImag/Bmp/Sample007\n",
      "Added: ./datasets/charset74k/Img/BadImag/Bmp/Sample008\n",
      "Added: ./datasets/charset74k/Img/BadImag/Bmp/Sample009\n",
      "Added: ./datasets/charset74k/Img/BadImag/Bmp/Sample010\n",
      "Added: ./datasets/charset74k/Img/BadImag/Bmp/Sample011\n",
      "Added: ./datasets/charset74k/Img/BadImag/Bmp/Sample012\n",
      "Added: ./datasets/charset74k/Img/BadImag/Bmp/Sample013\n",
      "Added: ./datasets/charset74k/Img/BadImag/Bmp/Sample014\n",
      "Added: ./datasets/charset74k/Img/BadImag/Bmp/Sample015\n",
      "Added: ./datasets/charset74k/Img/BadImag/Bmp/Sample016\n",
      "Added: ./datasets/charset74k/Img/BadImag/Bmp/Sample017\n",
      "Added: ./datasets/charset74k/Img/BadImag/Bmp/Sample018\n",
      "Added: ./datasets/charset74k/Img/BadImag/Bmp/Sample019\n",
      "Added: ./datasets/charset74k/Img/BadImag/Bmp/Sample020\n",
      "Added: ./datasets/charset74k/Img/BadImag/Bmp/Sample021\n",
      "Added: ./datasets/charset74k/Img/BadImag/Bmp/Sample022\n",
      "Added: ./datasets/charset74k/Img/BadImag/Bmp/Sample023\n",
      "Added: ./datasets/charset74k/Img/BadImag/Bmp/Sample024\n",
      "Added: ./datasets/charset74k/Img/BadImag/Bmp/Sample025\n",
      "Added: ./datasets/charset74k/Img/BadImag/Bmp/Sample026\n",
      "Added: ./datasets/charset74k/Img/BadImag/Bmp/Sample027\n",
      "Added: ./datasets/charset74k/Img/BadImag/Bmp/Sample028\n",
      "Added: ./datasets/charset74k/Img/BadImag/Bmp/Sample029\n",
      "Added: ./datasets/charset74k/Img/BadImag/Bmp/Sample030\n",
      "Added: ./datasets/charset74k/Img/BadImag/Bmp/Sample031\n",
      "Added: ./datasets/charset74k/Img/BadImag/Bmp/Sample032\n",
      "Added: ./datasets/charset74k/Img/BadImag/Bmp/Sample033\n",
      "Added: ./datasets/charset74k/Img/BadImag/Bmp/Sample034\n",
      "Added: ./datasets/charset74k/Img/BadImag/Bmp/Sample035\n",
      "Added: ./datasets/charset74k/Img/BadImag/Bmp/Sample036\n",
      "Added: ./datasets/charset74k/Img/BadImag/Bmp/Sample037\n",
      "Added: ./datasets/charset74k/Img/BadImag/Bmp/Sample038\n",
      "Added: ./datasets/charset74k/Img/BadImag/Bmp/Sample039\n",
      "Added: ./datasets/charset74k/Img/BadImag/Bmp/Sample040\n",
      "Added: ./datasets/charset74k/Img/BadImag/Bmp/Sample041\n",
      "Added: ./datasets/charset74k/Img/BadImag/Bmp/Sample042\n",
      "Added: ./datasets/charset74k/Img/BadImag/Bmp/Sample043\n",
      "Added: ./datasets/charset74k/Img/BadImag/Bmp/Sample044\n",
      "Added: ./datasets/charset74k/Img/BadImag/Bmp/Sample045\n",
      "Added: ./datasets/charset74k/Img/BadImag/Bmp/Sample046\n",
      "Added: ./datasets/charset74k/Img/BadImag/Bmp/Sample047\n",
      "Added: ./datasets/charset74k/Img/BadImag/Bmp/Sample048\n",
      "Added: ./datasets/charset74k/Img/BadImag/Bmp/Sample049\n",
      "Added: ./datasets/charset74k/Img/BadImag/Bmp/Sample050\n",
      "Added: ./datasets/charset74k/Img/BadImag/Bmp/Sample051\n",
      "Added: ./datasets/charset74k/Img/BadImag/Bmp/Sample052\n",
      "Added: ./datasets/charset74k/Img/BadImag/Bmp/Sample053\n",
      "Added: ./datasets/charset74k/Img/BadImag/Bmp/Sample054\n",
      "Added: ./datasets/charset74k/Img/BadImag/Bmp/Sample055\n",
      "Added: ./datasets/charset74k/Img/BadImag/Bmp/Sample056\n",
      "Added: ./datasets/charset74k/Img/BadImag/Bmp/Sample057\n",
      "Added: ./datasets/charset74k/Img/BadImag/Bmp/Sample058\n",
      "Added: ./datasets/charset74k/Img/BadImag/Bmp/Sample059\n",
      "Added: ./datasets/charset74k/Img/BadImag/Bmp/Sample060\n",
      "Added: ./datasets/charset74k/Img/BadImag/Bmp/Sample061\n",
      "Added: ./datasets/charset74k/Img/BadImag/Bmp/Sample062\n",
      "---------IMG ADDED----------\n",
      "Added: ./datasets/charset74k/Hnd/Img/Sample001\n",
      "Added: ./datasets/charset74k/Hnd/Img/Sample002\n",
      "Added: ./datasets/charset74k/Hnd/Img/Sample003\n",
      "Added: ./datasets/charset74k/Hnd/Img/Sample004\n",
      "Added: ./datasets/charset74k/Hnd/Img/Sample005\n",
      "Added: ./datasets/charset74k/Hnd/Img/Sample006\n",
      "Added: ./datasets/charset74k/Hnd/Img/Sample007\n",
      "Added: ./datasets/charset74k/Hnd/Img/Sample008\n",
      "Added: ./datasets/charset74k/Hnd/Img/Sample009\n",
      "Added: ./datasets/charset74k/Hnd/Img/Sample010\n",
      "Added: ./datasets/charset74k/Hnd/Img/Sample011\n",
      "Added: ./datasets/charset74k/Hnd/Img/Sample012\n",
      "Added: ./datasets/charset74k/Hnd/Img/Sample013\n",
      "Added: ./datasets/charset74k/Hnd/Img/Sample014\n",
      "Added: ./datasets/charset74k/Hnd/Img/Sample015\n",
      "Added: ./datasets/charset74k/Hnd/Img/Sample016\n",
      "Added: ./datasets/charset74k/Hnd/Img/Sample017\n",
      "Added: ./datasets/charset74k/Hnd/Img/Sample018\n",
      "Added: ./datasets/charset74k/Hnd/Img/Sample019\n",
      "Added: ./datasets/charset74k/Hnd/Img/Sample020\n",
      "Added: ./datasets/charset74k/Hnd/Img/Sample021\n",
      "Added: ./datasets/charset74k/Hnd/Img/Sample022\n",
      "Added: ./datasets/charset74k/Hnd/Img/Sample023\n",
      "Added: ./datasets/charset74k/Hnd/Img/Sample024\n",
      "Added: ./datasets/charset74k/Hnd/Img/Sample025\n",
      "Added: ./datasets/charset74k/Hnd/Img/Sample026\n",
      "Added: ./datasets/charset74k/Hnd/Img/Sample027\n",
      "Added: ./datasets/charset74k/Hnd/Img/Sample028\n",
      "Added: ./datasets/charset74k/Hnd/Img/Sample029\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added: ./datasets/charset74k/Hnd/Img/Sample030\n",
      "Added: ./datasets/charset74k/Hnd/Img/Sample031\n",
      "Added: ./datasets/charset74k/Hnd/Img/Sample032\n",
      "Added: ./datasets/charset74k/Hnd/Img/Sample033\n",
      "Added: ./datasets/charset74k/Hnd/Img/Sample034\n",
      "Added: ./datasets/charset74k/Hnd/Img/Sample035\n",
      "Added: ./datasets/charset74k/Hnd/Img/Sample036\n",
      "Added: ./datasets/charset74k/Hnd/Img/Sample037\n",
      "Added: ./datasets/charset74k/Hnd/Img/Sample038\n",
      "Added: ./datasets/charset74k/Hnd/Img/Sample039\n",
      "Added: ./datasets/charset74k/Hnd/Img/Sample040\n",
      "Added: ./datasets/charset74k/Hnd/Img/Sample041\n",
      "Added: ./datasets/charset74k/Hnd/Img/Sample042\n",
      "Added: ./datasets/charset74k/Hnd/Img/Sample043\n",
      "Added: ./datasets/charset74k/Hnd/Img/Sample044\n",
      "Added: ./datasets/charset74k/Hnd/Img/Sample045\n",
      "Added: ./datasets/charset74k/Hnd/Img/Sample046\n",
      "Added: ./datasets/charset74k/Hnd/Img/Sample047\n",
      "Added: ./datasets/charset74k/Hnd/Img/Sample048\n",
      "Added: ./datasets/charset74k/Hnd/Img/Sample049\n",
      "Added: ./datasets/charset74k/Hnd/Img/Sample050\n",
      "Added: ./datasets/charset74k/Hnd/Img/Sample051\n",
      "Added: ./datasets/charset74k/Hnd/Img/Sample052\n",
      "Added: ./datasets/charset74k/Hnd/Img/Sample053\n",
      "Added: ./datasets/charset74k/Hnd/Img/Sample054\n",
      "Added: ./datasets/charset74k/Hnd/Img/Sample055\n",
      "Added: ./datasets/charset74k/Hnd/Img/Sample056\n",
      "Added: ./datasets/charset74k/Hnd/Img/Sample057\n",
      "Added: ./datasets/charset74k/Hnd/Img/Sample058\n",
      "Added: ./datasets/charset74k/Hnd/Img/Sample059\n",
      "Added: ./datasets/charset74k/Hnd/Img/Sample060\n",
      "Added: ./datasets/charset74k/Hnd/Img/Sample061\n",
      "Added: ./datasets/charset74k/Hnd/Img/Sample062\n",
      "---------HAND ADDED----------\n",
      "Added: ./datasets/charset74k/Fnt/Sample001\n",
      "Added: ./datasets/charset74k/Fnt/Sample002\n",
      "Added: ./datasets/charset74k/Fnt/Sample003\n",
      "Added: ./datasets/charset74k/Fnt/Sample004\n",
      "Added: ./datasets/charset74k/Fnt/Sample005\n",
      "Added: ./datasets/charset74k/Fnt/Sample006\n",
      "Added: ./datasets/charset74k/Fnt/Sample007\n",
      "Added: ./datasets/charset74k/Fnt/Sample008\n",
      "Added: ./datasets/charset74k/Fnt/Sample009\n",
      "Added: ./datasets/charset74k/Fnt/Sample010\n",
      "Added: ./datasets/charset74k/Fnt/Sample011\n",
      "Added: ./datasets/charset74k/Fnt/Sample012\n",
      "Added: ./datasets/charset74k/Fnt/Sample013\n",
      "Added: ./datasets/charset74k/Fnt/Sample014\n",
      "Added: ./datasets/charset74k/Fnt/Sample015\n",
      "Added: ./datasets/charset74k/Fnt/Sample016\n",
      "Added: ./datasets/charset74k/Fnt/Sample029\n",
      "Added: ./datasets/charset74k/Fnt/Sample048\n",
      "Added: ./datasets/charset74k/Fnt/Sample049\n",
      "Added: ./datasets/charset74k/Fnt/Sample050\n",
      "Added: ./datasets/charset74k/Fnt/Sample051\n",
      "Added: ./datasets/charset74k/Fnt/Sample052\n",
      "Added: ./datasets/charset74k/Fnt/Sample053\n",
      "Added: ./datasets/charset74k/Fnt/Sample054\n",
      "Added: ./datasets/charset74k/Fnt/Sample055\n",
      "Added: ./datasets/charset74k/Fnt/Sample056\n",
      "Added: ./datasets/charset74k/Fnt/Sample057\n",
      "Added: ./datasets/charset74k/Fnt/Sample058\n",
      "Added: ./datasets/charset74k/Fnt/Sample059\n",
      "Added: ./datasets/charset74k/Fnt/Sample060\n",
      "Added: ./datasets/charset74k/Fnt/Sample061\n",
      "Added: ./datasets/charset74k/Fnt/Sample062\n",
      "---------FONT ADDED----------\n",
      "1000 In betweens\n",
      "2000 In betweens\n",
      "3000 In betweens\n",
      "4000 In betweens\n",
      "CIFAR10 Added\n"
     ]
    }
   ],
   "source": [
    "X,Y = prepare_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72ad7c73",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Config:\n",
    "    test_ratio = 0.1\n",
    "    validation_ratio = 0.1\n",
    "    learning_rate = 0.0001\n",
    "    batch_size = 64\n",
    "    epochs = 10\n",
    "    steps_per_epoch = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b779262b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, Y,\n",
    "                                                    test_size = Config.test_ratio,\n",
    "                                                    random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c174242",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_vald, y_train, y_vald = train_test_split(X_train,\n",
    "                                                    y_train, \n",
    "                                                    test_size = Config.validation_ratio,\n",
    "                                                    random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86a5c8ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(img):\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    img = cv2.equalizeHist(img)\n",
    "    img = img/255\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04fee5ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 3\n",
    "img = preprocess(X_train[i])\n",
    "img = cv2.resize(img, (300,300))\n",
    "f, axarr = plt.subplots(1, 2)\n",
    "axarr[0].imshow(X_train[i])\n",
    "axarr[1].imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cff867f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot(Y):\n",
    "    return tf.keras.utils.to_categorical(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0201f33a",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = one_hot(y_train)\n",
    "y_vald = one_hot(y_vald)\n",
    "y_test = one_hot(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6c11c80",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_arr(X):\n",
    "    X = np.array(list(map(preprocess, X)))\n",
    "    X = X.reshape(X.shape[0], X.shape[1], X.shape[2], 1)\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01ad4b6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = preprocess_arr(X_train)\n",
    "X_vald = preprocess_arr(X_vald)\n",
    "X_test = preprocess_arr(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4ddf5f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.Sequential()\n",
    "model.add(layers.Conv2D(96, kernel_size = (8,8), activation = 'relu', input_shape = (32,32,1)))\n",
    "model.add(layers.AveragePooling2D())\n",
    "\n",
    "model.add(layers.Conv2D(256, kernel_size = (8,8), activation = 'relu'))\n",
    "model.add(layers.AveragePooling2D())\n",
    "\n",
    "model.add(layers.Dropout(0.5))\n",
    "\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(512, activation = 'relu'))\n",
    "model.add(layers.Dropout(0.5))\n",
    "\n",
    "model.add(layers.Dense(2, activation = 'softmax'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ac6dbcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(tf.keras.optimizers.Adam(learning_rate = Config.learning_rate), \n",
    "              loss = \"categorical_crossentropy\",\n",
    "              metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "501803dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping = keras.callbacks.EarlyStopping(monitor = 'val_accuracy',min_delta = 0,patience = 2,mode = 'auto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87caf045",
   "metadata": {},
   "outputs": [],
   "source": [
    "hist = model.fit(X_train, y_train , \n",
    "                 batch_size = Config.batch_size, \n",
    "                 steps_per_epoch = Config.steps_per_epoch, \n",
    "                 epochs = Config.epochs, \n",
    "                 validation_data = (X_vald, y_vald),\n",
    "                 callbacks = [early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc5eae7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(1)\n",
    "plt.plot(hist.history['loss'])\n",
    "plt.plot(hist.history['val_loss'])\n",
    "plt.legend(['training', 'validation'])\n",
    "plt.title(\"Loss\")\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.figure(2)\n",
    "plt.plot(hist.history['accuracy'])\n",
    "plt.plot(hist.history['val_accuracy'])\n",
    "plt.legend(['training', 'validation'])\n",
    "plt.title(\"Accuracy\")\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "\n",
    "plt.show()\n",
    "scorce = model.evaluate(X_test, y_test, verbose = 0)\n",
    "print(f'TestLoss: {scorce[0]} | Test Accuracy: {scorce[1]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4205971c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"./models/model3.h5\") "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25019a2d",
   "metadata": {},
   "source": [
    "# -------------------------------------------------------- #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7bc8db9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "model = keras.models.load_model('./models/model3.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5f07ef5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def input_preprocess(img):\n",
    "    img = cv2.resize(img, (32,32))\n",
    "    img = preprocess(img)\n",
    "    img = img.reshape(1,32,32,1)\n",
    "    return np.array(img)\n",
    "\n",
    "# img = cv2.imread(\"./download.jpg\")\n",
    "# img = X_train[5]\n",
    "# print(model.predict(img))\n",
    "# f, axarr = plt.subplots(1, 2)\n",
    "# axarr[0].imshow(img)\n",
    "# axarr[1].imshow(input_preprocess(img).reshape(32,32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d480624d",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Some Helper Functions\n",
    "# !pip install imutils\n",
    "import imutils\n",
    "from imutils.object_detection import non_max_suppression\n",
    "def sliding_window(img, step, ws):\n",
    "    \"\"\"\n",
    "        Slides a window in the image.\n",
    "    \"\"\"\n",
    "    for y in range(0, image.shape[0] - ws[1], step):\n",
    "        for x in range(0, image.shape[1] - ws[0], step):\n",
    "            yield (x, y, image[y : y + ws[1], x : x + ws[0]])\n",
    "\n",
    "def image_pyramid(image, scale = 1.5,min_size = (32,32)):\n",
    "    \"\"\"\n",
    "        Creates a Image Pyramid of scale(default = 1.5) until min_size(default = (32,32))\n",
    "    \"\"\"\n",
    "    yield image\n",
    "    \n",
    "    while True:\n",
    "        #Dimension of the next image in the pyramid\n",
    "        w = int(image.shape[0]/scale)\n",
    "        image = imutils.resize(image, width = w)\n",
    "        \n",
    "        if image.shape[0] < min_size[1] or image.shape[1] < min_size[0]:\n",
    "            break\n",
    "        \n",
    "        yield image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d62a019b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Config(Config):\n",
    "    width = 600\n",
    "    scale = 1.5\n",
    "    ROI_size = (200,150) #Regoin of Interest\n",
    "    min_prob = 0.99\n",
    "    win_step = 16\n",
    "    input_size = (32,32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee8ac410",
   "metadata": {},
   "outputs": [],
   "source": [
    "org = cv2.imread(\"./download.jpg\")\n",
    "org = imutils.resize(org, width = Config.width)\n",
    "(H,W) = org.shape[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49875e41",
   "metadata": {},
   "outputs": [],
   "source": [
    "pyramid = image_pyramid(org, scale = Config.scale, min_size =Config.ROI_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "581d4157",
   "metadata": {},
   "outputs": [],
   "source": [
    "rois = []#Stores ROIS\n",
    "locs = []#Locations of ROIS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ace3c264",
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "\n",
    "for image in pyramid:\n",
    "    scale = W / float(image.shape[1])\n",
    "    \n",
    "    for (x,y, roiOrg) in sliding_window(image, Config.win_step, Config.ROI_size):\n",
    "        #SCAling\n",
    "        x = int(x * scale)\n",
    "        y = int(y * scale)\n",
    "        w = int(Config.ROI_size[0] * scale)\n",
    "        h = int(Config.ROI_size[1] * scale)\n",
    "        \n",
    "        roi = cv2.resize(roiOrg,Config.input_size)\n",
    "        roi = input_preprocess(roi)\n",
    "        \n",
    "        rois.append(roi)\n",
    "        locs.append((x,y, x +w, y + h))\n",
    "        \n",
    "#         clone = org.copy()\n",
    "#         cv2.rectangle(clone, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "#         cv2.imshow(\"VISZZ\", clone)\n",
    "#         cv2.imshow(\"ROI\", roiOrg)\n",
    "#         cv2.waitKey(0)\n",
    "end = time.time()\n",
    "print(f'Took {round(end - start,2)} s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93b16902",
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "pred = []\n",
    "# print(len(rois))\n",
    "\n",
    "for roi in rois:\n",
    "    pred.append(model.predict(roi))\n",
    "#     if len(pred) % 50 == 0:\n",
    "#         print(\"Processed: \" + str(len(pred)) + \" ROIS\")\n",
    "\n",
    "end = time.time()\n",
    "print(f\"This took {round(end - start, 2)}s.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93073929",
   "metadata": {},
   "outputs": [],
   "source": [
    "P = []\n",
    "for probs in pred:\n",
    "    P.append((\"Char\", probs[0][1]))\n",
    "pred = P"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4998afc",
   "metadata": {},
   "outputs": [],
   "source": [
    "chbox_prob = []\n",
    "for (i,p) in enumerate(pred):\n",
    "    (label, prob) = p\n",
    "#     print(prob)\n",
    "    if prob >= Config.min_prob:\n",
    "        box = locs[i]\n",
    "        chbox_prob.append((box, prob))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07dd014f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.patches import Rectangle\n",
    "plt.imshow(org)\n",
    "for chbox in chbox_prob:\n",
    "    box,prob = chbox\n",
    "    (startX, startY, endX, endY) = box\n",
    "    plt.gca().add_patch(Rectangle((startX, startY), endX - startX, endY - startY,\n",
    "                                 edgecolor = 'red',\n",
    "                                 facecolor = 'none',))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2203ba8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "boxes, probs = list(zip(*chbox_prob))\n",
    "boxes = np.array(boxes)\n",
    "probs = np.array(probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce4e0b25",
   "metadata": {},
   "outputs": [],
   "source": [
    "boxes = non_max_suppression(boxes,probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e90499c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(org)\n",
    "for startX, startY, endX, endY in boxes:\n",
    "    plt.gca().add_patch(Rectangle((startX, startY), endX - startX, endY - startY,\n",
    "                                 edgecolor = 'red',\n",
    "                                 facecolor = 'none'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "142fdaae",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
